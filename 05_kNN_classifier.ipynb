{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Machine Learning for music playlists: K-nearest neighbors classification\n",
    "This is the 5th post in a series of posts devoted to analysis of iTunes music library using Scikit-Learn tools.   \n",
    "The purpose of the analysis is to detect tracks in my iTunes music library that would suit my fitness practices, which are \"cycling\", \"yoga\", and \"ballet\". To solve that problem I use supervised ML classification techniques. \n",
    "\n",
    "Previous posts cover the following steps:\n",
    "* [00_Summary](http://localhost:8888/notebooks/00_Summary.ipynb) — Summary of this analysis, its goals and methods, installation notes.\n",
    "* [01_Data_preparation](http://localhost:8888/notebooks/01_Data_preparation.ipynb) — Data gathering and cleaning.\n",
    "* [02_Data_visualisation](http://localhost:8888/notebooks/02_Data_Visualisation.ipynb) — Visualisation and overview of data.\n",
    "* [03_Preprocessing](http://localhost:8888/notebooks/03_Preprocessing.ipynb) — Data preprocessing to use it as input for Scikit-learn machine learning algorithms.\n",
    "* [04_Novelty_detection](http://localhost:8888/notebooks/04_Novelty_detection.ipynb) — One-Class SVM algorithm to identify matching tracks in the unlabeled dataset.\n",
    "\n",
    "As a result of previous manipulations I have two tables in HDF5 format: \n",
    "* training set contains 88 tracks labeled with one of the three classes: \"ballet\", \"cycling\", \"yoga\". Labels are stored as a pandas Series;\n",
    "* test set contains 289 tracks labeled as matching the training set and 155 tracks as non-matching. In the [04_Novelty_detection](http://localhost:8888/notebooks/04_Novelty_detection.ipynb) NB I used One-Class SVM to choose tracks in the test set that match training data. As a result, each track was identified either as matching or not.\n",
    "\n",
    "In this post I apply [k neighbours classification](http://scikit-learn.org/stable/modules/neighbors.html#classification) to assign every track in the matching group one of the classes. \n",
    "\n",
    "As a shortcut, in this notebook I import module \"data_processing\" with functions from the [01_Data_preparation](http://localhost:8888/notebooks/01_Data_preparation.ipynb) and [03_Preprocessing](http://localhost:8888/notebooks/03_Preprocessing.ipynb) notebooks.  \n",
    "I start with importing the modules required in the following notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the future division statement\n",
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import my module from the previous notebook\n",
    "import data_processing as prs\n",
    "\n",
    "# set seaborn plot defaults\n",
    "import seaborn as sns; \n",
    "sns.set(palette=\"husl\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# format floating point numbers\n",
    "# within pandas data structures\n",
    "pd.set_option('float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: music_data.h5\n",
       "/knn_df               frame_table  (typ->appendable,nrows->289,ncols->14,indexers->[index])\n",
       "/target               series       (shape->[88])                                           \n",
       "/test_svm             frame_table  (typ->appendable,nrows->444,ncols->12,indexers->[index])\n",
       "/train_std            frame_table  (typ->appendable,nrows->88,ncols->11,indexers->[index]) "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open an hdf5 file\n",
    "store = pd.HDFStore('music_data.h5')\n",
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both sets are stored as pandas DataFrames. I convert these to numpy arrays because Scikit-Learn algorithms expect a numpy array as input. I also save index in the test set as a column when converting it to a numpy array. Thus it will be easier to identify each track after classification, where I'll be using only tracks labeled as matching. \n",
    "\n",
    "Data in both sets were standardized in the pre-processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get training data (standardized) and convert to numpy array\n",
    "train_std = prs.convert_df_to_array(store['train_std'])\n",
    "\n",
    "# get test data (standardized) and convert to numpy array\n",
    "test_std = prs.convert_df_to_array(store['test_svm'].reset_index())\n",
    "\n",
    "# matching tracks\n",
    "match_test = test_std[(test_std[:, 12] == 1)]\n",
    "\n",
    "# target data as numpy array\n",
    "target = store['target'].values\n",
    "\n",
    "# list class labels\n",
    "labels = ['ballet', 'cycling', 'yoga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data overview: \n",
      "Train data shape: (88, 11)\n",
      "Test data shape: (444, 13)\n",
      "Test data only with matching tracks: (289, 13)\n"
     ]
    }
   ],
   "source": [
    "print \"Data overview: \"\n",
    "print \"Train data shape:\", train_std.shape\n",
    "print \"Test data shape:\", test_std.shape\n",
    "print \"Test data only with matching tracks:\", match_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors classification\n",
    "Nearest neighbors classification algorithm computes a class for every query point (that is, unlabeled observation) based on a simple majority of class representatives within the nearest labeled neighbors. In Scikit_Learn [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) number of nearest neighbors of each query point — *k* — is specified in model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nearest neighbours algorithm\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process I use for classification task is as follows:\n",
    "1. Tune parameters using GridSearchCV.\n",
    "2. Create and train the model.\n",
    "3. Estimate model accuracy score.\n",
    "4. Make predictions and estimate probability.\n",
    "5. Record the result to the set and DF.\n",
    "6. Review the results.\n",
    "7. Apply probability threshold. \n",
    "\n",
    "### 1. Tune parameters using GridSearchCV\n",
    "[GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) performs an exhaustive search over specified parameter values for an estimator. I use it to test the desired range of input parameters, and review the performance of each set of values on a cross-validation basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.79545, std: 0.11954, params: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto'},\n",
       " mean: 0.79545, std: 0.11328, params: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto'},\n",
       " mean: 0.79545, std: 0.11954, params: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree'},\n",
       " mean: 0.79545, std: 0.11328, params: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree'},\n",
       " mean: 0.79545, std: 0.11954, params: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree'},\n",
       " mean: 0.79545, std: 0.11328, params: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree'},\n",
       " mean: 0.79545, std: 0.11954, params: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute'},\n",
       " mean: 0.79545, std: 0.11328, params: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute'},\n",
       " mean: 0.80682, std: 0.11825, params: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto'},\n",
       " mean: 0.80682, std: 0.11825, params: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree'},\n",
       " mean: 0.80682, std: 0.11825, params: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree'},\n",
       " mean: 0.80682, std: 0.11825, params: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute'},\n",
       " mean: 0.81818, std: 0.11593, params: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto'},\n",
       " mean: 0.81818, std: 0.11593, params: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree'},\n",
       " mean: 0.81818, std: 0.11593, params: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree'},\n",
       " mean: 0.81818, std: 0.11593, params: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute'},\n",
       " mean: 0.82955, std: 0.12676, params: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto'},\n",
       " mean: 0.82955, std: 0.12676, params: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree'},\n",
       " mean: 0.82955, std: 0.12676, params: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree'},\n",
       " mean: 0.82955, std: 0.12676, params: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute'},\n",
       " mean: 0.84091, std: 0.12716, params: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto'},\n",
       " mean: 0.84091, std: 0.12716, params: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree'},\n",
       " mean: 0.84091, std: 0.12716, params: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree'},\n",
       " mean: 0.84091, std: 0.12716, params: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# tune parameters\n",
    "parameter_grid = {'n_neighbors': [3, 5, 7],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                 'algorithm': ['auto', 'ball_tree', \n",
    "                               'kd_tree', 'brute']}\n",
    "\n",
    "grid_search = GridSearchCV(neighbors.KNeighborsClassifier(), \n",
    "                           parameter_grid, cv=6)\n",
    "\n",
    "grid_search.fit(train_std, target)\n",
    "\n",
    "# review the result\n",
    "sorted(grid_search.grid_scores_, \n",
    "       key=lambda x: x.mean_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best-performing tuning parameters\n",
      "Best score: 0.8409;\n",
      "Best parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto'}.\n"
     ]
    }
   ],
   "source": [
    "# define the winner\n",
    "knn_best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print (\"The best-performing tuning parameters\"\n",
    "       \"\\nBest score: {0:.4f};\"\n",
    "       \"\\nBest parameters: {1}.\"\n",
    "       .format(knn_best_score, \n",
    "               best_params\n",
    "              ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create and train the model\n",
    "Next I create a model using the parameters defined by GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_neighbors=7, p=2, weights='distance')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "n_neighbors = best_params['n_neighbors']\n",
    "weights = best_params['weights']\n",
    "algorithm = best_params['algorithm']\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, \n",
    "                                     weights=weights, \n",
    "                                     algorithm=algorithm)\n",
    "\n",
    "# train the model\n",
    "knn.fit(train_std, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Estimate model accuracy score\n",
    "One of the most important pieces of machine learning is model validation: that is, checking how well the model fits a given dataset. I can not automatically assess the accuracy of predictions made for the test set, because it is non-labeled data. A better way to test a model is to use a hold-out part of the labeled set which doesn't enter the training.  \n",
    "\n",
    "Scikit-Learn provides a great tool for model validation — [K-fold cross-validation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score) module, which splits the data into K chunks and performs K fits, where each chunk gets a turn as the validation set. K is defined by the cv parameter. I use 10-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# calculate model accuracy score\n",
    "cvs = cross_val_score(knn, train_std, target, \n",
    "                    scoring='accuracy', cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-neighbors classification model accuracy score: 0.786\n",
      "Model report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     ballet       0.76      0.74      0.75        34\n",
      "    cycling       0.84      1.00      0.91        31\n",
      "       yoga       0.78      0.61      0.68        23\n",
      "\n",
      "avg / total       0.79      0.80      0.79        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a text report showing the main classification metrics\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "    \n",
    "predicted = cross_val_predict(knn, train_std, \n",
    "                            target, cv=10)\n",
    "\n",
    "print (\"K-neighbors classification model \"\n",
    "       \"accuracy score: {:.3f}\"\n",
    "       .format(cvs))\n",
    "print \"Model report \\n\", \n",
    "print classification_report(target, predicted, \n",
    "                            target_names=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me explain the above numbers. \n",
    "\n",
    "The *precision* is the ratio of true positives to the sum of true and false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.  \n",
    "In this case \"cycling\" class has the highest precision. That means that the pureness of model prediction for that class is 84% (16% of tracks assigned this class have a different label), whereas for the \"ballet\" class it equals 76%, which still is pretty high.\n",
    "\n",
    "The *recall* is the ratio of true positives to the sum of true positives and false negatives. The recall is intuitively the ability of the classifier to find all the positive samples. \n",
    "The \"cycling\" class has the highest possible score. All tracks belonging to that class were identified correctly by the model. The \"yoga\" class has the lowest ratio. The precision ratio, however, is rather high. That means that just 22% of tracks assigned the \"yoga\" class had a different label but at the same time 40% of tracks with the \"yoga\" label were assigned a different class.  \n",
    "\n",
    "The *F1-score* can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "The *support* is the number of occurrences of each class in y_true. This is the number of tracks in each class. \n",
    "\n",
    "The overall accuracy of the model is high. The \"cycling\" class proves itself as the easiest to predict and the \"yoga\", on the contrary, has the least accurate predictions.\n",
    "\n",
    "### 4. Make predictions and estimate probability\n",
    "Satisfied with the model performance on the training set, I apply it to the test set to make predictions using predict method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "# exclude index and novelty result\n",
    "knn_output = knn.predict(match_test[:, 1:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest neighbors classifier has predict_proba method that can predict the probability of class membership. For every query point it will calculate the probablity of belonging to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_prob(model, test_data):\n",
    "    \"\"\"Calculate probability for \n",
    "    every class and return an array\n",
    "    with highest probability for each\n",
    "    track. \n",
    "    \"\"\"\n",
    "    probability = model.predict_proba(test_data)\n",
    "    \n",
    "    # make a list of highest probabilities\n",
    "    max_proba = np.asarray([x.max() for x in probability])\n",
    "    return max_proba[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classification probability\n",
    "knn_prob = class_prob(knn, match_test[:, 1:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Record the result\n",
    "I add the model prediction and probability to the matching set and then to the DF. I store the resulting dataframe as a hdf5 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(289, 15)\n",
      "\n",
      "Sample of the resulting set: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.20843788,  0.63488137,  1.25808605, -0.88779748,\n",
       "        -0.49132844,  0.78719594, -1.1740436 , -0.39262975, -0.74488995,\n",
       "         0.43101536,  0.57687657,  1.        ,  1.        ,  0.66406856],\n",
       "       [ 1.        , -0.2793643 , -0.95059729, -0.59717964,  1.12009741,\n",
       "         1.26151896,  0.17775694, -1.1740436 , -0.80693268,  0.63767235,\n",
       "        -0.87689333, -0.01472446,  1.        ,  0.        ,  0.83478127],\n",
       "       [ 2.        ,  0.72038789,  1.90749621, -0.54831972,  1.14486486,\n",
       "         0.38509526, -0.33955242,  0.85175712, -0.08956489,  0.29581684,\n",
       "         0.43101536,  1.24591181,  1.        ,  0.        ,  0.53629557]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the result to the matching set\n",
    "knn_set = np.concatenate((match_test, knn_output[:, None], knn_prob), 1)\n",
    "\n",
    "# review the result\n",
    "print knn_set.shape\n",
    "print \"\\nSample of the resulting set: \"\n",
    "knn_set[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the set back into pandas dataframe\n",
    "def nparray_to_df(data, store):\n",
    "    \"\"\"Transform dataset in numpy array format to a df.\n",
    "    Return the df.\n",
    "    \"\"\"\n",
    "    # make a list of column names\n",
    "    li = (['index'] + \n",
    "          store['train_std'].columns.tolist() + \n",
    "          ['match', 'label', 'prob'])\n",
    "    \n",
    "    # transform set into a DF\n",
    "    df = pd.DataFrame(data, columns=li)\n",
    "    \n",
    "    # change column type to integer\n",
    "    df[['index', 'match', 'label']] = df[['index', 'match', 'label']].astype(int)\n",
    "    \n",
    "    # change index to the original index\n",
    "    df = df.set_index(['index'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>match</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>-0.72</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.14</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-1.22</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.53</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acousticness  danceability  energy  instrumentalness   key  loudness  \\\n",
       "index                                                                         \n",
       "148           -0.66          0.39    1.11             -0.91 -0.20      0.70   \n",
       "359           -0.72          1.87    1.14             -0.91 -1.66      1.02   \n",
       "145           -1.22          0.36    1.53             -0.91  0.09      1.22   \n",
       "\n",
       "       mode  speechiness  tempo  time_signature  valence  match  label  prob  \n",
       "index                                                                         \n",
       "148   -1.17        -0.52   0.06            0.43     0.69      1      1  0.59  \n",
       "359   -1.17        -0.26  -0.04            0.43     1.54      1      1  0.85  \n",
       "145   -1.17        -0.77  -0.61            0.43     1.47      1      1  0.87  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a df for data with KNN results\n",
    "knn_df = nparray_to_df(knn_set, store)\n",
    "\n",
    "# review the result\n",
    "knn_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save in HDF5\n",
    "knn_df.to_hdf('music_data.h5', 'knn_df', format='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Review the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_summary(df, model, model_name, labels, cvs):\n",
    "    print (\"Summary of the {} classifier \"\n",
    "           \"performance\\n\".format(model_name))\n",
    "    print \"Model: \"\n",
    "    print model\n",
    "    print (\"\\nModel accuracy score: {:.3f}\"\n",
    "           .format(cvs))\n",
    "    # drop 'match' column as it's not relevant here\n",
    "    df = df.drop('match', 1)\n",
    "    print (\"\\nNumber of tracks in the test set: {}.\"\n",
    "           .format(len(df)))\n",
    "    for lb in labels:\n",
    "        print (\"Number of tracks assigned to the \\\"{}\\\" class: {}, or {:.2%} of all tracks.\"\n",
    "               .format(lb, len(df[df['label'] == labels.index(lb)]),\n",
    "                      (len(df[df['label'] == labels.index(lb)])/len(df))))\n",
    "    print \"\\nMean probability for each category\"\n",
    "    grouped = df.groupby(['label'])\n",
    "    print grouped['prob'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the K-Nearest Neighbors classifier performance\n",
      "\n",
      "Model: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_neighbors=7, p=2, weights='distance')\n",
      "\n",
      "Model accuracy score: 0.786\n",
      "\n",
      "Number of tracks in the test set: 289.\n",
      "Number of tracks assigned to the \"ballet\" class: 112, or 38.75% of all tracks.\n",
      "Number of tracks assigned to the \"cycling\" class: 172, or 59.52% of all tracks.\n",
      "Number of tracks assigned to the \"yoga\" class: 5, or 1.73% of all tracks.\n",
      "\n",
      "Mean probability for each category\n",
      "label\n",
      "0   0.72\n",
      "1   0.83\n",
      "2   0.64\n",
      "Name: prob, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print the summary\n",
    "model_summary(knn_df, knn, 'K-Nearest Neighbors', labels, cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"cycling\" class has the highest mean probability, which means that on average tracks are assigned this class with 83% certainty. At the same time this is the most popular class — almost 60% of all tracks in the test set are assigned the \"cycling\" class. \n",
    "\n",
    "The \"ballet\" class is doing alright. Almost 40% of all tracks are assigned this class label with 72% certainty on average. \n",
    "\n",
    "The \"yoga\" class has the fewest representatives in the test set. Only 5 tracks were assigned this class label. The mean probability is the lowest among the three classes (63%).  \n",
    "\n",
    "### 6. Apply probability threshold\n",
    "In my playlists I want to keep only tracks with high probability of class membership. To decide on the threshold for  probability estimate I plot number of tracks in each class with a threshold varying from 0 to 100%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_with_threshold(df, threshold):\n",
    "    \"\"\"Returns a df with class probability\n",
    "    higher than a threshold.\n",
    "    \"\"\"\n",
    "    # drop 'match' column as it's not relevant here\n",
    "    df = df.drop('match', 1)\n",
    "    \n",
    "    prob_thres = df[df['prob'] >= threshold]\n",
    "    return prob_thres\n",
    "\n",
    "def sum_category(df, index):\n",
    "    \"\"\"Returns number of tracks in a category\n",
    "    \"\"\"\n",
    "    category_size = len(df[df['label'] == index])\n",
    "    return category_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAFqCAYAAAD7mDhwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11561af90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# threshold values\n",
    "xs = list(a / 10.0 for a in range(11))\n",
    "\n",
    "# all classes\n",
    "total = [len(prob_with_threshold(knn_df, i)) for i in xs]\n",
    "line_total = plt.plot(xs, total, linewidth=2, label='total')\n",
    "\n",
    "for lb in labels:\n",
    "    lb_sum = [sum_category(prob_with_threshold(knn_df, i), \n",
    "                             labels.index(lb)) for i in xs]\n",
    "    line_lb = plt.plot(xs, lb_sum, linewidth=2, label=lb)\n",
    "\n",
    "plt.ylabel('Number of tracks')\n",
    "plt.xlabel('Probability')\n",
    "plt.legend()\n",
    "sns.despine(top=True, right=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot, I'd say that 0.7 is a good value for the probability threshold. It filters out some tracks in each class, eliminating tracks with lower certainty of class membership and, thus, making the playlists more accurate. Setting the value to 0.8 and higher leaves the \"yoga\" class without any tracks at all and excludes big part of tracks in two other classes. \n",
    "\n",
    "I apply the 0.7 probability threshold to data and review the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary_of_prob_with_thres(df, threshold, labels):\n",
    "    df_prob = prob_with_threshold(df, threshold)\n",
    "    print (\"Total number of tracks to classify: {}.\"\n",
    "           .format(len(df)))\n",
    "    print (\"Number of tracks with {} probability \"\n",
    "          \"of class membership: {}.\"\n",
    "          .format(threshold, len(df_prob)))\n",
    "    print \"Among which...\"\n",
    "    for lb in labels:\n",
    "        print (\"...assigned the \\\"{}\\\" class: {} ({} without the threshold).\"\n",
    "               .format(lb, len(df_prob[df_prob['label'] == labels.index(lb)]),\n",
    "                      len(df[df['label'] == labels.index(lb)])))\n",
    "    print \"\\nMean probability for each class\"\n",
    "    grouped = df_prob.groupby(['label'])\n",
    "    print grouped['prob'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa139b12e426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary_of_prob_with_thres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'knn_df' is not defined"
     ]
    }
   ],
   "source": [
    "# print summary \n",
    "summary_of_prob_with_thres(knn_df, 0.7, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook I applied **k-neighbors classification** tecnique to identify class membership of every track in the matching group and assign a class label. I started by tuning model parameters using scikit-learn tool GridSearchCV. I estimated model accuracy using K-fold cross validation tecnique.  \n",
    "\n",
    "The estimated **model accuracy score** equals **0.786**.  \n",
    "\n",
    "Model prediction results: \n",
    "* \"ballet\" class: 112, or 38.75% of all tracks.\n",
    "* \"cycling\" class: 172, or 59.52% of all tracks.\n",
    "* \"yoga\" class: 5, or 1.73% of all tracks.\n",
    "\n",
    "The \"cycling\" class has the highest mean probability, which means that on average tracks are assigned this class with 83% certainty. At the same time this is the most popular class — almost 60% of all tracks in the test set are assigned the \"cycling\" class. \n",
    "\n",
    "The \"ballet\" class is doing alright. Almost 40% of all tracks are assigned this class label with 72% certainty on average. \n",
    "\n",
    "The \"yoga\" class has the fewest representatives in the test set. Only 5 tracks were assigned this class label. The mean probability is the lowest among the three classes (63%).\n",
    "\n",
    "I applied 0.7 probability threshold to model predictions of class membership. As a result the \"ballet\" class lost 35% of tracks (73 are left), the \"cycling\" class lost about 24% (131 tracks left), and the \"yoga\" class is left with only 2 tracks (60% lost).\n",
    "\n",
    "I saved all functions used in this notebook as a module 'estimator_handling.py'. I'm going to use it in the following notebooks. Data and results of this classification are stored in a HDF5 file. \n",
    "\n",
    "In the next post I'm going to try Random Forest Classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
