{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iTunes music library analysis: Novelty Detection\n",
    "This is the 4th post in a series of posts devoted to analysis of iTunes music library using Scikit-Learn tools.   \n",
    "The purpose of the analysis is to detect tracks in my iTunes music library that would suit my fitness practices, which are \"cycling\", \"yoga\", and \"ballet\". To solve that problem I use machine learning classification algorithms.    \n",
    "\n",
    "The previous posts cover the following steps:\n",
    "1. [00_Summary]() — Summary of this analysis, its goals and methods, installation notes.\n",
    "2. [01_Data_preparation]() — Data gathering and cleaning.\n",
    "3. [02_Data_visualisation]() — Visualisation and overview of data.\n",
    "4. [03_Preprocessing]() — Data preprocessing to use it as input for Scikit-learn machine learning algorithms.\n",
    "\n",
    "As a result of previous manipulations I have two databases (DBs): \n",
    "* training DB contains 88 tracks labeled with one of the three classes: \"ballet\", \"cycling\", \"yoga\";\n",
    "* test DB contains 444 non-labeled tracks. \n",
    "\n",
    "The three classes I have in the training set don't cover all classes of music I have in my iTunes music library (test DB). Because of that I can't apply a classification algorithm to the whole test set as it will also assign irrelevant tracks to some class.  \n",
    "\n",
    "In the following notebook I'm going to identify tracks in the unlabeled dataset that fit classes in the training dataset and eliminate tracks that completely unfit the classes. Only then I will perform classification.  \n",
    "\n",
    "As a shortcut, in this notebook I import module \"data_processing.py\" where I perform steps from the [01_Data_preparation]() and [03_Preprocessing]() notebooks.  \n",
    "I start with importing the modules required in the following notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlitedict import SqliteDict\n",
    "\n",
    "# import my module from the previous notebook\n",
    "import data_processing as prs\n",
    "\n",
    "# set seaborn plot defaults\n",
    "import seaborn as sns; \n",
    "sns.set(palette=\"husl\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# format floating point numbers\n",
    "# within pandas data structures\n",
    "pd.set_option('float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-578cb0d24938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# convert both df's to numpy arrays with standardized features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m train_std, test_std = prs.standardize_data(prs.convert_df_to_array(train_df), \n\u001b[0m\u001b[1;32m     13\u001b[0m                                            prs.convert_df_to_array(test_df))\n",
      "\u001b[0;32m/Users/olgamedennikova/projects/music_analysis/data_processing.py\u001b[0m in \u001b[0;36mconvert_df_to_array\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;31m# convert df to a numerical (Numpy) array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# training DB\n",
    "train_db = SqliteDict('./labeled_tracks')\n",
    "# create a df with training data\n",
    "train_df = prs.read_db_in_pandas(train_db)\n",
    "\n",
    "# test DB\n",
    "test_db = SqliteDict('./itunes_tracks')\n",
    "# create a df with test data\n",
    "test_df = prs.read_db_in_pandas(test_db)\n",
    "\n",
    "# convert both df's to numpy arrays with standardized features\n",
    "train_std, test_std = prs.standardize_data(prs.convert_df_to_array(train_df), \n",
    "                                           prs.convert_df_to_array(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my purpose I use [One-Class SVM](http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM) unsupervised algorithm. One-Class SVM is used for novelty detection, that is, given a set of samples (training set), it will detect the soft boundary of that set so as to classify new points (test set) as belonging to that set or not. It's important to point out that the algorithm treats the training data as not polluted by outliers.  \n",
    "\n",
    "I use the following parameters: radial basis function, or 'rbf', kernel; 'nu' value has been chosen by trial and error method. 'nu' value is an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-228d6af75be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneClassSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rbf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.07\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_std' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# fit the model\n",
    "svm_model = svm.OneClassSVM(kernel=\"rbf\", nu=0.07)\n",
    "svm_model.fit(train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New observations, or test data, can now be sorted as inliers or outliers with a predict method. Inliers are labeled 1, while outliers are labeled -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make prediction\n",
    "test_novelty_pred = svm_model.predict(test_std)\n",
    "\n",
    "# number of tracks outside set boudaries\n",
    "n_error_test = test_novelty_pred[test_novelty_pred == -1].size\n",
    "\n",
    "print (\"Number of tracks that match the training set: {0}.\"\n",
    "       \"\\nNumber of tracks outside set boudaries: {1}.\"\n",
    "       .format((test_novelty_pred.size - n_error_test), \n",
    "               n_error_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
