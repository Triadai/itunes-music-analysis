{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Machine Learning for music playlists: Data preparation\n",
    "\n",
    "This is the first post in a series of posts devoted to building music playlists with Scikit-Learn tools.   \n",
    "This notebook covers data gathering and preparation and cleaning of the datasets I'm going to use in my analysis.\n",
    "For the overview of this analysis, its goals, methods, and installation notes please go to [00_Overview](https://github.com/Tykovka/itunes-music-analysis/blob/master/00_Overview.ipynb). \n",
    "\n",
    "#### Contents of the notebook\n",
    "* [Machine Learning Intro](#Machine-Learning-Intro)\n",
    "* [Preliminaries](#Preliminaries)\n",
    "* [Data preparation](#Data-preparation)\n",
    "* [Data overview](#Data-overview)\n",
    "* [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Machine-Learning-Intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Intro\n",
    "In this analysis, I'm interested in three classes of music (\"cycling\", \"ballet\", \"yoga\") and I want to find tracks in my iTunes music library that fit these classes. This is a multiclass classification problem. Classification is the task of predicting the value of a categorical variable given some input variables (the features). \n",
    "\n",
    "To solve that problem I use *supervised machine learning classification algorithms*.  \n",
    "\n",
    "Supervised machine learning is about creating models from data: a model learns from training data (data with class labels), and can be used to predict the result of test data (data without class labels). Thus, the task of supervised learning is to construct an estimator which is able to predict the label of an object given the set of features. One can also think of classification as a function estimation problem where the function that we want to estimate separates the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Preliminaries'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "One of the main goals of this analysis is to explore the basics of Scikit-Learn tools. **[Scikit-Learn](http://scikit-learn.org)** is a popular Python package designed to give access to well-known machine learning algorithms within Python code. \n",
    "\n",
    "Scikit-Learn is built upon Python's **[NumPy (Numerical Python)](http://www.numpy.org/)** and **[SciPy (Scientific Python)](http://scipy.org/)** libraries, which enable efficient in-core numerical and scientific computation within Python. \n",
    "\n",
    "I also use **[pandas](http://pandas.pydata.org/)** library in my analysis. Pandas is a Python package providing fast, flexible, and expressive data structures. It is a fundamental high-level building block for doing practical, real-world data analysis in Python.\n",
    "\n",
    "The hero and the foundation of my analysis is the **[Echo Nest API](http://the.echonest.com/)**, which provides broad and deep data on millions of artists and songs. **[Pyechonest](https://github.com/echonest/pyechonest)** is an open source Python library for the Echo Nest API that I use in this analysis. To use The Echo Nest API, an API key is required. More about the API key [here](http://developer.echonest.com/raw_tutorials/register.html).\n",
    "\n",
    "I start with importing modules required in the following notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# format floating point numbers\n",
    "# within pandas data structures\n",
    "pd.set_option('float_format', '{:.2f}'.format)\n",
    "\n",
    "# import pyechonest\n",
    "from pyechonest import config\n",
    "\n",
    "# pass my API key\n",
    "config.ECHO_NEST_API_KEY=\"MY_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data-preparation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data preparation\n",
    "In the analysis I use two datasets:\n",
    "1. iTunes music library serves me as a *test dataset*, or non-labelled data;\n",
    "2. For the *training dataset* I made a CSV file ('./labeled_tracks.csv') with hand picked tracks outside of my iTunes library. I labelled each track with one of the three classes: \"cycling\", \"yoga\", \"ballet\". \n",
    "\n",
    "iTunes library files track the media in iTunes. The iTunes library file, a file called iTunes Music Library.xml, is created automatically when you launch iTunes. 'iTunes Music Library.xml' contains information that's stored in the iTunes database of the songs in the library. On Mac OS X, it can be found in the directory 'Users/username/Music/iTunes'. More information about iTunes library files can be found [here](https://support.apple.com/en-us/HT201610).\n",
    "\n",
    "Throughout the analysis, I use pandas DataFrame (DF) data structure, which one can think of as an Excel-like table of values. DataFrames have various methods that can be called to easily learn about the data contained in them. \n",
    "\n",
    "To store data and results of my computations I use **[HDF5](http://pandas.pydata.org/pandas-docs/stable/io.html#io-hdf5)** format. HDF5 allows to treat a local file as a hash and work directly with pandas DataFrames. Very cool. It's trivial to read and write from this file using Pandas. \n",
    "### Test dataset\n",
    "I will start by processing the test data.  \n",
    "\n",
    "To parse iTunes XML file I use **[pyItunes](https://github.com/liamks/pyitunes)** module, which makes it easier to access tracks in the XML file. \n",
    "\n",
    "HDF5 is not suitable for writing in data row by row. Though the test set is not as big (not millions of songs), when getting data from the Echo Nest API I will need to append rows. After several failed attempts to write all data right into a pandas DF, I switched to a sqlite3 database (DB).\n",
    "\n",
    "I use the **[sqlitedict](https://github.com/piskvorky/sqlitedict)** library to access it. sqlitedict is a lightweight wrapper around Python's sqlite3 DB with a simple, Pythonic dict-like interface. For this particular problem, I think using a DB is more convenient than a CSV or XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlitedict import SqliteDict\n",
    "# create a DB to store data from iTunes library\n",
    "test_db = SqliteDict('./itunes_tracks_db', autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_itunes_track_data(song):\n",
    "    \"\"\"Check the validity of the track, \n",
    "    exclude podcasts and tracks \n",
    "    missing artist's name.\n",
    "    \"\"\"\n",
    "    if (song.genre == 'Podcast' or \n",
    "        song.genre == u'iTunesÂ U' or \n",
    "        song.kind != 'MPEG audio file' or \n",
    "        not song.artist): \n",
    "        return None \n",
    "    else:\n",
    "        return song.name, song.artist\n",
    "\n",
    "def parse_itunes_xml(xml_file, db):\n",
    "    \"\"\"Parse xml, get song's title\n",
    "    and artist's name, save to a DB.\n",
    "    \"\"\"\n",
    "    from pyItunes import Library\n",
    "    l = Library(xml_file)\n",
    "    \n",
    "    # index will serve as a key for the dict\n",
    "    ind = 0\n",
    "    \n",
    "    for id, song in l.songs.items():\n",
    "        try:\n",
    "            song_title, artist = get_itunes_track_data(song)\n",
    "            db[ind] = {'song': song_title, \n",
    "                       'artist': artist}\n",
    "            ind += 1\n",
    "        except TypeError as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# path to the iTunes xml file (I copied it)\n",
    "xml_file = 'iTunes Music Library copy.xml'\n",
    "\n",
    "# write the data into the DB\n",
    "parse_itunes_xml(xml_file, test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset contains 669 tracks.\n"
     ]
    }
   ],
   "source": [
    "# review the result\n",
    "print (\"Test dataset contains {} tracks.\"\n",
    "       .format(len(test_db)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to get song attributes from the Echo Nest API and to write them in the DB.\n",
    "\n",
    "In the analysis I use the following track attributes, which are available through the Echo Nest API:\n",
    "\n",
    "* **Acousticness** represents the likelihood a recording was created by solely acoustic means such as voice and acoustic instruments as opposed to electronically such as with synthesized, amplified or effected instruments;\n",
    "* **Danceability** describes how suitable a track is for dancing using a number of musical elements (tempo, rhythm stability, beat strength, and overall regularity);\n",
    "* **Energy** represents a perceptual measure of intensity and powerful activity released throughout the track;\n",
    "* **Instrumentalnes** is a measure of how likely a song is to be instrumental;\n",
    "* **Key** identifies the tonic triad, the chord, major or minor. Key signatures start at 0 (C) and ascend the chromatic scale;\n",
    "* **Loudness** measures the overall loudness of a track in decibels (dB);\n",
    "* **Mode** indicates the modality (major (1) or minor (0)) of a track, the type of scale from which its melodic content is derived;\n",
    "* **Speechiness** detects the presence of spoken words in a track;\n",
    "* **Tempo** is the speed or pace of a given piece (in beats per minute);\n",
    "* **Time signature** specifies how many beats are in each measure;\n",
    "* **Valence** describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g., happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of features to use in the analysis\n",
    "features = ['acousticness',\n",
    "            'danceability',\n",
    "            'energy',\n",
    "            'instrumentalness',\n",
    "            'key',\n",
    "            'loudness',\n",
    "            'mode',\n",
    "            'speechiness',\n",
    "            'tempo',\n",
    "            'time_signature',\n",
    "            'valence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Echo Nest Python library Pyechonest is super easy and straightforward. The Echo Nest database doesn't provide data for every artist or song. I handle missing items with a \"try-except\" block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_song_data(artist_name, song_title):\n",
    "    \"\"\"Get track features data from \n",
    "    the Echo Nest database.\n",
    "    \"\"\"\n",
    "    from pyechonest import song\n",
    "    try: \n",
    "        result = song.search(artist=artist_name, \n",
    "                             title=song_title)\n",
    "        song_result = result[0]\n",
    "        song_data = song_result.audio_summary\n",
    "        \n",
    "        # returns a dictionary of song features\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError as e:\n",
    "        return None\n",
    "         \n",
    "def add_features_to_db(db, features):\n",
    "    \"\"\"Request track features from\n",
    "    the Echo Nest database and add to the DB.\n",
    "    \"\"\"\n",
    "    from time import sleep\n",
    "    \n",
    "    for key, value in db.iteritems():\n",
    "        # check if attributes have been already added\n",
    "        if value.get('tempo'):\n",
    "            pass\n",
    "        else:\n",
    "            song_data = get_song_data(value['artist'],\n",
    "                                     value['song'])\n",
    "            # if the song is in the Echo Nest DB, \n",
    "            # I add data to the DB\n",
    "            if song_data:\n",
    "                for f in features:\n",
    "                    value.update({f : song_data[f]})\n",
    "                db[key] = value\n",
    "            \n",
    "            # if not, I delete the track\n",
    "            else:\n",
    "                del db[key]\n",
    "        # the Echo Nest limits number of requests to 20 per minute\n",
    "        sleep(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I call the function to add track features from the Echo Nest data to the DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add features\n",
    "add_features_to_db(test_db, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset contains 537 tracks.\n"
     ]
    }
   ],
   "source": [
    "# view the resulting DF\n",
    "print (\"Test dataset contains {} tracks.\"\n",
    "       .format(len(test_db)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the data I transform the set to pandas DF. I transpose data to have songs as rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 537 entries, 0 to 98\n",
      "Data columns (total 13 columns):\n",
      "acousticness        537 non-null object\n",
      "artist              537 non-null object\n",
      "danceability        537 non-null object\n",
      "energy              537 non-null object\n",
      "instrumentalness    536 non-null object\n",
      "key                 537 non-null object\n",
      "loudness            537 non-null object\n",
      "mode                537 non-null object\n",
      "song                537 non-null object\n",
      "speechiness         536 non-null object\n",
      "tempo               537 non-null object\n",
      "time_signature      537 non-null object\n",
      "valence             537 non-null object\n",
      "dtypes: object(13)\n",
      "memory usage: 58.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# read DB\n",
    "test_df = pd.DataFrame(dict(test_db)).T\n",
    "\n",
    "# view the result\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above gives us an overview of data in DF columns. There are 537 tracks, or rows, in the test set. Tracks with no data in the Echo Nest database were removed from the test set when calling *add_features_to_db* function.  \n",
    "\n",
    "However, one track in the resulting set has no data for the instrumentalness feature. Pandas provides various tools for handling [missing data](http://pandas.pydata.org/pandas-docs/stable/missing_data.html). I simply remove the row with no data for the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop the row\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have 11 numeric features (these are the data from the Echo Nest) and 2 columns with text data in the test set. I notice, however, that all features were identified as objects. I convert these columns to the numerical format. I also reorder columns to move \"artist\" and \"song\" feature to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acousticness',\n",
       " 'danceability',\n",
       " 'energy',\n",
       " 'instrumentalness',\n",
       " 'key',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'speechiness',\n",
       " 'tempo',\n",
       " 'time_signature',\n",
       " 'valence',\n",
       " 'artist',\n",
       " 'song']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to numerical format\n",
    "test_df = test_df.convert_objects(convert_numeric=True)\n",
    "\n",
    "# list of columns\n",
    "cols = test_df.columns.tolist()\n",
    "\n",
    "# reorder the list\n",
    "cols = cols[0:1] + cols[2:8] + cols[9:] + cols[1:2] + cols[8:9]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply new order to the list\n",
    "test_df = test_df.ix[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 535 entries, 0 to 98\n",
      "Data columns (total 13 columns):\n",
      "acousticness        535 non-null float64\n",
      "danceability        535 non-null float64\n",
      "energy              535 non-null float64\n",
      "instrumentalness    535 non-null float64\n",
      "key                 535 non-null int64\n",
      "loudness            535 non-null float64\n",
      "mode                535 non-null int64\n",
      "speechiness         535 non-null float64\n",
      "tempo               535 non-null float64\n",
      "time_signature      535 non-null int64\n",
      "valence             535 non-null float64\n",
      "artist              535 non-null object\n",
      "song                535 non-null object\n",
      "dtypes: float64(8), int64(3), object(2)\n",
      "memory usage: 58.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# view the result\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I reordered columns in the test set, fixed type of data, and removed rows with missing values. As a result, I have a dataframe with 536 observations (rows) and 13 features (columns). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.37</td>\n",
       "      <td>125.12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>Caravan Palace</td>\n",
       "      <td>Jolie Coquine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>118.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.59</td>\n",
       "      <td>Caribou</td>\n",
       "      <td>Odessa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>115.45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.56</td>\n",
       "      <td>Jenny Wilson</td>\n",
       "      <td>Like A Fading Rainbow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>117.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Heartbreak</td>\n",
       "      <td>Loving The Alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>177.57</td>\n",
       "      <td>4</td>\n",
       "      <td>0.54</td>\n",
       "      <td>High Contrast</td>\n",
       "      <td>Kiss Kiss Bang Band</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness  danceability  energy  instrumentalness  key  loudness  \\\n",
       "0            0.01          0.71    0.95              0.00    4     -5.08   \n",
       "1            0.00          0.67    0.50              0.03    0    -20.45   \n",
       "10           0.01          0.57    0.45              0.04    0     -7.88   \n",
       "100          0.01          0.80    0.69              0.01    2     -5.80   \n",
       "102          0.16          0.57    0.82              0.76   10     -5.40   \n",
       "\n",
       "     mode  speechiness  tempo  time_signature  valence          artist  \\\n",
       "0       1         0.37 125.12               4     0.60  Caravan Palace   \n",
       "1       1         0.05 118.01               4     0.59         Caribou   \n",
       "10      1         0.05 115.45               4     0.56    Jenny Wilson   \n",
       "100     0         0.04 117.00               4     0.41      Heartbreak   \n",
       "102     0         0.06 177.57               4     0.54   High Contrast   \n",
       "\n",
       "                      song  \n",
       "0            Jolie Coquine  \n",
       "1                   Odessa  \n",
       "10   Like A Fading Rainbow  \n",
       "100       Loving The Alien  \n",
       "102    Kiss Kiss Bang Band  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that the index of the dataframe has \"gaps\". The reason is that, when writing features to the test database, I deleted tracks with no data in the Echo Nest base. To fix it I reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.37</td>\n",
       "      <td>125.12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>Caravan Palace</td>\n",
       "      <td>Jolie Coquine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>118.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.59</td>\n",
       "      <td>Caribou</td>\n",
       "      <td>Odessa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>115.45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.56</td>\n",
       "      <td>Jenny Wilson</td>\n",
       "      <td>Like A Fading Rainbow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>117.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Heartbreak</td>\n",
       "      <td>Loving The Alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>177.57</td>\n",
       "      <td>4</td>\n",
       "      <td>0.54</td>\n",
       "      <td>High Contrast</td>\n",
       "      <td>Kiss Kiss Bang Band</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  energy  instrumentalness  key  loudness  mode  \\\n",
       "0          0.01          0.71    0.95              0.00    4     -5.08     1   \n",
       "1          0.00          0.67    0.50              0.03    0    -20.45     1   \n",
       "2          0.01          0.57    0.45              0.04    0     -7.88     1   \n",
       "3          0.01          0.80    0.69              0.01    2     -5.80     0   \n",
       "4          0.16          0.57    0.82              0.76   10     -5.40     0   \n",
       "\n",
       "   speechiness  tempo  time_signature  valence          artist  \\\n",
       "0         0.37 125.12               4     0.60  Caravan Palace   \n",
       "1         0.05 118.01               4     0.59         Caribou   \n",
       "2         0.05 115.45               4     0.56    Jenny Wilson   \n",
       "3         0.04 117.00               4     0.41      Heartbreak   \n",
       "4         0.06 177.57               4     0.54   High Contrast   \n",
       "\n",
       "                    song  \n",
       "0          Jolie Coquine  \n",
       "1                 Odessa  \n",
       "2  Like A Fading Rainbow  \n",
       "3       Loving The Alien  \n",
       "4    Kiss Kiss Bang Band  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset index\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set is now ready for further analysis. I move to the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset\n",
    "\n",
    "For the training dataset, I made a CSV file ('./labeled_tracks.csv') with hand picked tracks and labelled each track with one of the three classes: \"cycling\", \"ballet\", \"yoga\".\n",
    "\n",
    "I use pandas read_csv function to read the CSV file into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# path to the csv file\n",
    "csv_file = './labeled_tracks.csv'\n",
    "\n",
    "# transform the csv file to a DF\n",
    "train_data = pd.read_csv(csv_file, encoding='utf_8', \n",
    "                       header=0)\n",
    "\n",
    "# add features as empty columns\n",
    "for f in features:\n",
    "    train_data[f] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset contains 163 tracks.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 163 entries, 0 to 162\n",
      "Data columns (total 14 columns):\n",
      "song                163 non-null object\n",
      "artist              163 non-null object\n",
      "category            163 non-null object\n",
      "acousticness        0 non-null float64\n",
      "danceability        0 non-null float64\n",
      "energy              0 non-null float64\n",
      "instrumentalness    0 non-null float64\n",
      "key                 0 non-null float64\n",
      "loudness            0 non-null float64\n",
      "mode                0 non-null float64\n",
      "speechiness         0 non-null float64\n",
      "tempo               0 non-null float64\n",
      "time_signature      0 non-null float64\n",
      "valence             0 non-null float64\n",
      "dtypes: float64(11), object(3)\n",
      "memory usage: 19.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# review the result\n",
    "print (\"Training dataset contains {} tracks.\"\n",
    "       .format(len(train_data)))\n",
    "print \n",
    "print train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I make a function to write data from the Echo Nest to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_features_to_df(df, features):\n",
    "    \"\"\"Request track features from\n",
    "    the Echo Nest database and add to the DF.\n",
    "    \"\"\"\n",
    "    from time import sleep\n",
    "    \n",
    "    for i in df.index.tolist():\n",
    "        # check if attributes have been already added\n",
    "        if pd.notnull(df.loc[i, 'tempo']): \n",
    "            pass\n",
    "        else:\n",
    "            song_data = get_song_data(df.loc[i, 'artist'], \n",
    "                                      df.loc[i, 'song'])\n",
    "            \n",
    "            # if the song is in the Echo Nest DB, \n",
    "            # I add data to the DF.\n",
    "            if song_data:\n",
    "                for f in features:\n",
    "                    df.loc[i, f] = song_data[f]\n",
    "            # if not, I drop the track. \n",
    "            else:\n",
    "                df = df.drop(i)\n",
    "        # the Echo Nest limits number of requests to 20 per minute\n",
    "        sleep(7) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add features to the training DF\n",
    "train_df = add_features_to_df(train_data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 0 to 162\n",
      "Data columns (total 14 columns):\n",
      "song                143 non-null object\n",
      "artist              143 non-null object\n",
      "category            143 non-null object\n",
      "acousticness        143 non-null float64\n",
      "danceability        143 non-null float64\n",
      "energy              143 non-null float64\n",
      "instrumentalness    143 non-null float64\n",
      "key                 143 non-null float64\n",
      "loudness            143 non-null float64\n",
      "mode                143 non-null float64\n",
      "speechiness         141 non-null float64\n",
      "tempo               143 non-null float64\n",
      "time_signature      143 non-null float64\n",
      "valence             143 non-null float64\n",
      "dtypes: float64(11), object(3)\n",
      "memory usage: 16.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# get info about data\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above gives an overview of data in training DF columns. There are 143 rows in the training set. Tracks with no data in the Echo Nest database were removed from the set when calling *add_features_to_df* function.  \n",
    "\n",
    "However, two tracks in the resulting set have no data for the speechiness feature. Being familiar with the features, I know that this particular feature is not very valuable for the analysis. At the same time having more observations toI simply leave the missing data as is.\n",
    "\n",
    "I know that three features \"key\", \"mode\", and \"time_signature\" are discrete, not continuous as other features, with a limited number of values. E.g. \"time_signature\" has 4 values: 1, 3, 4 or 5. I change type of these three features to integer instead of float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 0 to 162\n",
      "Data columns (total 14 columns):\n",
      "song                143 non-null object\n",
      "artist              143 non-null object\n",
      "category            143 non-null object\n",
      "acousticness        143 non-null float64\n",
      "danceability        143 non-null float64\n",
      "energy              143 non-null float64\n",
      "instrumentalness    143 non-null float64\n",
      "key                 143 non-null int64\n",
      "loudness            143 non-null float64\n",
      "mode                143 non-null int64\n",
      "speechiness         141 non-null float64\n",
      "tempo               143 non-null float64\n",
      "time_signature      143 non-null int64\n",
      "valence             143 non-null float64\n",
      "dtypes: float64(8), int64(3), object(3)\n",
      "memory usage: 16.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df[['key', 'mode', 'time_signature']] = train_df[['key', 'mode', 'time_signature']].astype(int)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I reorder columns in the training set to keep the order consistent with the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acousticness',\n",
       " 'danceability',\n",
       " 'energy',\n",
       " 'instrumentalness',\n",
       " 'key',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'speechiness',\n",
       " 'tempo',\n",
       " 'time_signature',\n",
       " 'valence',\n",
       " u'song',\n",
       " u'artist',\n",
       " u'category']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_df.columns.tolist()\n",
    "cols = cols[3:] + cols[:3]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change order of columns\n",
    "train_df = train_df.ix[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 0 to 162\n",
      "Data columns (total 14 columns):\n",
      "acousticness        143 non-null float64\n",
      "danceability        143 non-null float64\n",
      "energy              143 non-null float64\n",
      "instrumentalness    143 non-null float64\n",
      "key                 143 non-null int64\n",
      "loudness            143 non-null float64\n",
      "mode                143 non-null int64\n",
      "speechiness         141 non-null float64\n",
      "tempo               143 non-null float64\n",
      "time_signature      143 non-null int64\n",
      "valence             143 non-null float64\n",
      "song                143 non-null object\n",
      "artist              143 non-null object\n",
      "category            143 non-null object\n",
      "dtypes: float64(8), int64(3), object(3)\n",
      "memory usage: 16.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is now ready for further analysis. I save both sets on disk in HDF5 format.\n",
    "\n",
    "### Save datasets in HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save test df \n",
    "test_df.to_hdf('music_data.h5', 'test_df', min_itemsize = {'values': 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save training df\n",
    "train_df.to_hdf('music_data.h5', 'train_df', min_itemsize = {'values': 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.pytables.HDFStore'>\n",
      "File path: music_data.h5\n",
      "/test_df             frame        (shape->[536,13])\n",
      "/train_df            frame        (shape->[143,12])\n"
     ]
    }
   ],
   "source": [
    "# check the result\n",
    "print pd.HDFStore('music_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data-overview'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview  \n",
    "  \n",
    "I have two datasets with track attributes data from the Echo Nest API. Next step is to take a look at what I'm working with.\n",
    "### Test data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 536 tracks in the test dataset.\n",
      "\n",
      "Below is a random sample of the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>-7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.54</td>\n",
       "      <td>LCMDF</td>\n",
       "      <td>Future Me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>108.97</td>\n",
       "      <td>4</td>\n",
       "      <td>0.62</td>\n",
       "      <td>The Black Keys</td>\n",
       "      <td>Tighten Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>151.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Junip</td>\n",
       "      <td>Turn to the Assassin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness  danceability  energy  instrumentalness  key  loudness  \\\n",
       "98           0.03          0.62    0.90              0.00    7     -7.11   \n",
       "376          0.00          0.46    0.69              0.00    6     -6.13   \n",
       "275          0.62          0.49    0.56              0.76    2     -8.70   \n",
       "\n",
       "     mode  speechiness  tempo  time_signature  valence          artist  \\\n",
       "98      1         0.04 100.00               4     0.54           LCMDF   \n",
       "376     0         0.08 108.97               4     0.62  The Black Keys   \n",
       "275     1         0.03 151.01               3     0.27           Junip   \n",
       "\n",
       "                     song  \n",
       "98              Future Me  \n",
       "376            Tighten Up  \n",
       "275  Turn to the Assassin  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"There are {} tracks in the test dataset.\\n\"\n",
    "       .format(len(test_df)))\n",
    "print \"Below is a random sample of the dataset.\"\n",
    "test_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 163 tracks in the CSV file.\n",
      "20 tracks have no data available in the Echo Nest API.\n",
      "We are left with 143 tracks to use as training data.\n",
      "\n",
      "Below is a random sample of the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>-31.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>88.79</td>\n",
       "      <td>4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>Mental boy</td>\n",
       "      <td>Thomas Newman</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.84</td>\n",
       "      <td>6</td>\n",
       "      <td>-19.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>they move on tracks of never-ending light</td>\n",
       "      <td>this will destroy you</td>\n",
       "      <td>yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>176.97</td>\n",
       "      <td>4</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Five Seconds</td>\n",
       "      <td>Twin Shadow</td>\n",
       "      <td>cycling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness  danceability  energy  instrumentalness  key  loudness  \\\n",
       "156          0.94          0.17    0.07              0.96    4    -31.64   \n",
       "72           0.55          0.64    0.19              0.84    6    -19.37   \n",
       "39           0.00          0.47    0.88              0.01    1     -5.09   \n",
       "\n",
       "     mode  speechiness  tempo  time_signature  valence  \\\n",
       "156     1         0.03  88.79               4     0.15   \n",
       "72      1         0.04 120.00               4     0.07   \n",
       "39      1         0.06 176.97               4     0.64   \n",
       "\n",
       "                                          song                 artist category  \n",
       "156                                 Mental boy          Thomas Newman     yoga  \n",
       "72   they move on tracks of never-ending light  this will destroy you     yoga  \n",
       "39                                Five Seconds            Twin Shadow  cycling  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"There are {} tracks in the CSV file.\\n\"\n",
    "       \"{} tracks have no data available \"\n",
    "       \"in the Echo Nest API.\\n\"\n",
    "       \"We are left with {} tracks to use as training data.\\n\"\n",
    "       .format(len(train_data), \n",
    "               (len(train_data) - len(train_df)),\n",
    "              len(train_df)))\n",
    "print \"Below is a random sample of the dataset.\"\n",
    "train_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks in the dataset belong to 3 classes: ballet, cycling, yoga.\n",
      "49 tracks represent 'ballet' class.\n",
      "45 tracks represent 'cycling' class.\n",
      "49 tracks represent 'yoga' class.\n"
     ]
    }
   ],
   "source": [
    "# list of categories\n",
    "categories = list(pd.unique(train_df.category.ravel()))\n",
    "\n",
    "print (\"Tracks in the dataset belong \" \n",
    "       \"to {} classes: {}.\"\n",
    "       .format(len(categories), \", \".join(categories)))\n",
    "\n",
    "# count tracks in each category\n",
    "cat_count = pd.value_counts(train_df.category.ravel())\n",
    "\n",
    "# print categories\n",
    "for category in categories:\n",
    "    print (\"{} tracks represent \\'{}\\' class.\"\n",
    "           .format(cat_count[category], category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Summary'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook I described data gathering and cleaning process for further analysis. I parsed iTunes music library XML file to create a dataframe as a test dataset. I also transformed the CSV file with labeled tracks to a dataframe as a training set. Using the Echo Nest API I got track attributes for both sets.\n",
    "\n",
    "As a result of the above manipulations I created two pandas dataframes: \n",
    "* train dataframe contains 143 tracks labelled with one of the three classes â \"ballet\", \"cycling\", \"yoga\";\n",
    "* test dataframe contains 536 non-labelled tracks. \n",
    "\n",
    "Each set has 11 music attributes for every song which I'm going to analyse in the following posts.\n",
    "\n",
    "The next step in my analysis is to visualize both datasets and examine track attributes, which I cover in the next post [02_Data_visualisation](https://github.com/Tykovka/itunes-music-analysis/blob/master/02_Data_Visualisation.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
