{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iTunes music library analysis: Data preparation\n",
    "\n",
    "This is the first post in a series of posts devoted to analysis of iTunes music library using Scikit-Learn tools.   \n",
    "This notebook covers data gathering and preparation and cleaning of the datasets I'm going to use in my analysis.\n",
    "For the summary of this analysis, its goals, methods, and installation notes please go to [link](). \n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "One of the main goals of this analysis is to explore the basics of Scikit-Learn tools. **[Scikit-Learn](http://scikit-learn.org)** is a popular Python package designed to give access to well-known machine learning algorithms within Python code.\n",
    "\n",
    "Scikit-Learn is built upon Python's **[NumPy (Numerical Python)](http://www.numpy.org/)** and **[SciPy (Scientific Python)](http://scipy.org/)** libraries, which enable efficient in-core numerical and scientific computation within Python. \n",
    "\n",
    "I also use **[pandas](http://pandas.pydata.org/)** library in my analysis. Pandas is a Python package providing fast, flexible, and expressive data structures. It is a fundamental high-level building block for doing practical, real world data analysis in Python.\n",
    "\n",
    "The hero and the foundation of my analysis is the **[Echo Nest API](http://the.echonest.com/)**, which provides broad and deep data on millions of artists and songs. **[Pyechonest](https://github.com/echonest/pyechonest)** is an open source Python library for the Echo Nest API that I use in this analysis. To use The Echo Nest API, an API key is required. More about the API key [here](http://developer.echonest.com/raw_tutorials/register.html).\n",
    "\n",
    "I start with importing the modules required in the following notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: replace the API key with MY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# import pyechonest\n",
    "from pyechonest import config\n",
    "\n",
    "# pass my API key\n",
    "config.ECHO_NEST_API_KEY=\"1RNDIJ5SITBKZFDCT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "In this analysis I'm dealing with classification problem. Classification is the task of predicting the value of a categorical variable given some input variables (the features). \n",
    "\n",
    "I'm interested in three classes of music (\"cycling\", \"yoga\", \"ballet\") and I want to find tracks in my iTunes music library that fit these classes. To solve that problem I use *supervised machine learning classification algorithms*.  \n",
    "\n",
    "Supervised machine learning is about creating models from data: a model learns from training data (data with class labels), and can be used to predict the result of test data (data without class labels). Thus the task of supervised learning is to construct an estimator which is able to predict the label of an object given the set of features.\n",
    "\n",
    "For the analysis I use two datasets:\n",
    "1. iTunes music library serves me as a *test dataset*;\n",
    "2. For the *training dataset* I made a csv file ('./labeled_tracks.csv') with hand picked tracks outside of my iTunes library. I labeled each track with one of the three classes: \"cycling\", \"yoga\", \"ballet\". \n",
    "\n",
    "iTunes library files track the media in iTunes. The iTunes library file, a file called iTunes Music Library.xml, is created automatically when you launch iTunes. 'iTunes Music Library.xml' contains information that's stored in the iTunes database of the songs in the library. On Mac OS X, it can be found in the directory 'Users/username/Music/iTunes'. More information about iTunes library files can be found [here](https://support.apple.com/en-us/HT201610).\n",
    "\n",
    "For both datasets I use a sqlite3 database (DB) and use the **[sqlitedict](https://github.com/piskvorky/sqlitedict)** library to access it. sqlitedict is a lightweight wrapper around Python's sqlite3 DB with a simple, Pythonic dict-like interface. For this particular problem I think using a DB is more convenient than a CSV or XML file. \n",
    "\n",
    "### Test dataset\n",
    "I will start by processing the test data.  \n",
    "\n",
    "To parse iTunes xml file I use **[pyItunes](https://github.com/liamks/pyitunes)** module, which makes it easier to access tracks in the xml file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_itunes_track_data(song):\n",
    "    \"\"\"check the validity of the track, \n",
    "    exclude podcasts and tracks \n",
    "    missing artist's name.\n",
    "    \"\"\"\n",
    "    if (song.genre == 'Podcast' or \n",
    "        song.genre == u'iTunesÂ U' or \n",
    "        song.kind != 'MPEG audio file' or \n",
    "        not song.artist): \n",
    "        return None \n",
    "    else:\n",
    "        return song.name, song.artist\n",
    "\n",
    "def parse_itunes_xml(db, xml_file):\n",
    "    \"\"\"parse xml, get song's title\n",
    "    and artist's name, save to a database.\n",
    "    \"\"\"\n",
    "    from pyItunes import Library\n",
    "    l = Library(xml_file)\n",
    "    \n",
    "    for id, song in l.songs.items():\n",
    "        try:\n",
    "            song_title, artist = get_itunes_track_data(song)\n",
    "            if not db.get(song_title):\n",
    "                db[song_title] = {'artist' : artist}\n",
    "        except TypeError as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlitedict import SqliteDict\n",
    "\n",
    "# path to the iTunes xml file (I copied it)\n",
    "xml_file = 'iTunes Music Library copy.xml'\n",
    "\n",
    "# create a DB to store data from iTunes library\n",
    "test_db = SqliteDict('./itunes_tracks', \n",
    "                     autocommit=True)\n",
    "\n",
    "# call parse_itunes_xml function and \n",
    "# write the data into the DB.\n",
    "parse_itunes_xml(test_db, xml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB contains 617 tracks.\n"
     ]
    }
   ],
   "source": [
    "# view the resulting DB\n",
    "print (\"The DB contains {} tracks.\"\n",
    "       .format(len(test_db)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to get song attributes from the Echo Nest API.  \n",
    "\n",
    "In the analysis I use the following track attributes:\n",
    "\n",
    "* **Acousticness** represents the likelihood a recording was created by solely acoustic means such as voice and acoustic instruments as opposed to electronically such as with synthesized, amplified, or effected instruments;\n",
    "* **Danceability** describes how suitable a track is for dancing using a number of musical elements (tempo, rhythm stability, beat strength, and overall regularity);\n",
    "* **Energy** represents a perceptual measure of intensity and powerful activity released throughout the track;\n",
    "* **Instrumentalnes** is a measure of how likely a song is to be instrumental;\n",
    "* **Key** identifies the tonic triad, the chord, major or minor;\n",
    "* **Loudness** measureas the overall loudness of a track in decibels (dB);\n",
    "* **Mode** indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived;\n",
    "* **Speechiness** detects the presence of spoken words in a track;\n",
    "* **Tempo** is the speed or pace of a given piece (in beats per minute);\n",
    "* **Time signature** specifies how many beats are in each bar (or measure);\n",
    "* **Valence** describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g., happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "\n",
    "Using the Echo Nest Python library Pyechonest is super easy and straighforward.  \n",
    "\n",
    "The Echo Nest database doesn't provide data for every artist or song. I handle missing items with a \"try-except\" block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_track_attr_data(artist_name, song_title):\n",
    "    \"\"\"Get track attributes data from \n",
    "    the Echo Nest database.\n",
    "    \"\"\"\n",
    "    from pyechonest import song\n",
    "    try: \n",
    "        result = song.search(artist=artist_name, \n",
    "                             title=song_title)\n",
    "        song_result = result[0]\n",
    "        song_data = song_result.audio_summary\n",
    "        \n",
    "        # returns a dictionary of song attributes\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError as e:\n",
    "        print \"No data for the song\", song_title\n",
    "        return None\n",
    "    \n",
    "def pick_track_attr(song_data):\n",
    "    \"\"\"Pick required track attributes from a dict\n",
    "    I got from the Echo Nest library.\n",
    "    \"\"\"\n",
    "    song_val = {'time_signature' : song_data['time_signature'],\n",
    "                'energy' : song_data['energy'],\n",
    "                'tempo' : song_data['tempo'], \n",
    "                'speechiness' : song_data['speechiness'],\n",
    "                'acousticness' : song_data['acousticness'], \n",
    "                'danceability' : song_data['danceability'],\n",
    "                'instrumentalness' : song_data['instrumentalness'],\n",
    "                'key' : song_data['key'],\n",
    "                'loudness' : song_data['loudness'],\n",
    "                'valence' : song_data['valence'],\n",
    "                'mode' : song_data['mode']}\n",
    "    \n",
    "    return song_val\n",
    "         \n",
    "def set_echonest_attributes(db):\n",
    "    \"\"\"Look for new tracks in the DB, request  \n",
    "    track attributes from the Echo Nest library \n",
    "    and save to the db.\n",
    "    \"\"\"\n",
    "    from time import sleep\n",
    "\n",
    "    for song_title, value in db.iteritems():\n",
    "        # Check if the attributes have been already added\n",
    "        if value.get('tempo') or value.get('No_data'): \n",
    "            pass\n",
    "        else:\n",
    "            print song_title\n",
    "            song_data = get_track_attr_data(value['artist'], \n",
    "                                            song_title)\n",
    "            \n",
    "            # If the song is in the Echo Nest DB, \n",
    "            # I add the data to the DB.\n",
    "            if song_data:\n",
    "                song_val = pick_track_attr(song_data)\n",
    "                value.update(song_val)\n",
    "                db[song_title] = value\n",
    "            # If not, I add 'No_data' key to the song. \n",
    "            else:\n",
    "                song_val = {'No_data' : True}\n",
    "                value.update(song_val)\n",
    "                db[song_title] = value\n",
    "            # Echo Nest limits number of requests to 20 per minute\n",
    "            sleep(8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# call set_echonest_attributes function and \n",
    "# write the Echo Nest data into the iTunes DB.\n",
    "set_echonest_attributes(test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB contains 617 tracks.\n",
      "Example of values for the track \"Moon river\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acousticness': 0.853775,\n",
       " 'artist': 'Andrea Ross',\n",
       " 'danceability': 0.204634,\n",
       " 'energy': 0.248916,\n",
       " 'instrumentalness': 0.00198,\n",
       " 'key': 8,\n",
       " 'loudness': -11.155,\n",
       " 'mode': 1,\n",
       " 'speechiness': 0.03465,\n",
       " 'tempo': 155.866,\n",
       " 'time_signature': 3,\n",
       " 'valence': 0.185901}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the resulting DB\n",
    "print (\"The DB contains {} tracks.\"\n",
    "       .format(len(test_db)))\n",
    "print \"Example of values for the track \\\"Moon river\\\":\"\n",
    "test_db['Moon river']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset\n",
    "\n",
    "For the training dataset I made a csv file ('./labeled_tracks.csv') with hand picked tracks and labaled each track with one of the three classes: \"cycling\", \"yoga\", \"ballet\".\n",
    "\n",
    "I use pandas read_csv function to read the csv file and write it into the sqlite3 dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_tracks_from_csv(csv_file, db):\n",
    "    \"\"\"Transform the csv file into a pandas dataframe,\n",
    "    save data to a new DB for training data.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(csv_file, index_col='song', \n",
    "                       encoding='utf_8', header=0)\n",
    "    for item in data.index.tolist():\n",
    "        artist = data.loc[item, 'artist']\n",
    "        # category column contains class label\n",
    "        song_cat = data.loc[item, 'category']\n",
    "        if not db.get(item):\n",
    "            db[item] = {'artist' : artist, 'category' : song_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# path to the csv file\n",
    "csv_file = './labeled_tracks.csv'\n",
    "\n",
    "# create a DB to store training data from the csv file\n",
    "train_db = SqliteDict('./labeled_tracks', autocommit=True)\n",
    "\n",
    "# call parse_tracks_from_csv function\n",
    "parse_tracks_from_csv(csv_file, train_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ronds De Jambe a Terre\n",
      "Monochrome\n",
      "Romeo & Juliet: Dance of the Knights\n",
      "Dark Paradise\n",
      "Skinny Love\n",
      "Summertime sadness\n",
      "Time To Say Goodbye (Con Te Partiro)\n",
      "Winter\n",
      "Possibly Maybe\n",
      "Still\n",
      "Round de Jambe\n",
      "Rond De Jambe a Terre\n",
      "Piano Ballet Bare\n",
      "No data for the song Piano Ballet Bare\n",
      "Tendu 6/8\n",
      "Shelter\n",
      "Another love\n",
      "The Blower's Daughter\n",
      "Torn\n",
      "Not about angels\n",
      "Younger\n",
      "Ambre\n",
      "Flaws\n",
      "Lighthouse\n",
      "Return To\n",
      "Song For Zula\n",
      "Unravel\n",
      "I can't go for that\n",
      "Kesson Daslef\n",
      "Lay your cards out\n",
      "Running Up that hill\n",
      "Let Her Go\n",
      "Cross Hands\n",
      "Third\n",
      "Save Yourself\n",
      "SexyBack\n",
      "Time to dance\n",
      "Inferno\n",
      "Sacrilege\n",
      "Sirens\n",
      "Ten-Twenty-Ten\n",
      "Five Seconds\n",
      "This sweet love\n",
      "Undercover Martyn\n",
      "Farewell, stars\n",
      "Heads Will Roll\n",
      "Climbing Walls\n",
      "The world is ours\n",
      "When They Fight, They Fight\n",
      "Mr. Brightside\n",
      "The Wire\n",
      "Lost on me\n",
      "Emergency\n",
      "1957\n",
      "Where you at\n",
      "Help me run away\n",
      "Sister of pearl\n",
      "Too Much time together\n",
      "I wear glasses\n",
      "TV Queen\n",
      "Apple Pie Bed\n",
      "Follow\n",
      "All My Loving\n",
      "You make my dreams come true\n",
      "Baby Blue\n",
      "Holding Out For A Hero\n",
      "You spin me round (like a record)\n",
      "Dream 13 (minus even)\n",
      "Moments in love\n",
      "An Ending\n",
      "Abandon Window\n",
      "Flowers for Yulia\n",
      "River flows in you\n",
      "Bless Those Tired Eyes\n",
      "they move on tracks of never-ending light\n",
      "petrichor\n",
      "Gusts of Wind Blowing in Different Directions\n",
      "Intro\n",
      "Plinty\n",
      "Piano Textures II, II\n",
      "No data for the song Piano Textures II, II\n",
      "I\n",
      "Bless This Morning Year\n",
      "Breathe\n",
      "No data for the song Breathe\n",
      "Sleepy Time\n",
      "No data for the song Sleepy Time\n",
      "Yoga, Meditation and Relaxation\n",
      "No data for the song Yoga, Meditation and Relaxation\n",
      "Small Memory\n",
      "A Lovely Place to Be\n",
      "The Sun I\n",
      "An Intro...\n",
      "No data for the song An Intro...\n",
      "Aurora\n",
      "A Meaningful Moment Through a Meaning(less) Process\n",
      "D 92 8:50 P.M\n",
      "No data for the song D 92 8:50 P.M\n",
      "You\n",
      "Path 5 (delta)\n",
      "No data for the song Path 5 (delta)\n",
      "Piano Textures: III\n",
      "Song of the Sea\n",
      "The Mother's Portrait\n",
      "No data for the song The Mother's Portrait\n",
      "The Derry Tune\n",
      "The Storm\n",
      "No data for the song The Storm\n"
     ]
    }
   ],
   "source": [
    "# write the Echo Nest data into the training DB\n",
    "#TODO: uncomment\n",
    "set_echonest_attributes(train_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB contains 98 tracks.\n",
      "Example of values for the track \"Five Seconds\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acousticness': 0.001899,\n",
       " 'artist': u'Twin Shadow',\n",
       " 'category': u'cycling',\n",
       " 'danceability': 0.467563,\n",
       " 'energy': 0.879714,\n",
       " 'instrumentalness': 0.007045,\n",
       " 'key': 1,\n",
       " 'loudness': -5.086,\n",
       " 'mode': 1,\n",
       " 'speechiness': 0.057028,\n",
       " 'tempo': 176.972,\n",
       " 'time_signature': 4,\n",
       " 'valence': 0.64461}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the resulting DB\n",
    "print (\"The DB contains {} tracks.\"\n",
    "       .format(len(train_db)))\n",
    "print \"Example of values for the track \\\"Five Seconds\\\":\"\n",
    "train_db['Five Seconds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview  \n",
    "  \n",
    "I have two DBs with track attributes data from the Echo Nest API. Next step is to read in data from both DBs and take a look at what I'm working with.\n",
    "\n",
    "I transform DBs into pandas dataframes (DF), which one can think of as an Excel-like table of values. Dataframes have various methods that can be called to easily learn about the data contained in them. I leave in the DF only tracks with  attributes data for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_db_in_pandas(db):\n",
    "    \"\"\" Read the DB and return a DF.\n",
    "    \"\"\"\n",
    "    # transpose data to have tracks as rows\n",
    "    df = pd.DataFrame(dict(db)).T\n",
    "    \n",
    "    # remove rows with no data for a song\n",
    "    df_clean = df[df['No_data'] != 1]\n",
    "    \n",
    "    # convert columns into numbers\n",
    "    df_clean = df_clean.convert_objects(convert_numeric=True)\n",
    "    \n",
    "    # convert index into a column\n",
    "    df_clean.reset_index(level=0, inplace=True)\n",
    "    df_clean.rename(columns = {'index': 'song_title'}, \n",
    "                    inplace=True)\n",
    "\n",
    "    # remove the 'No_data' column\n",
    "    df_clean.drop('No_data', 1, \n",
    "                  inplace=True)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a df with training data\n",
    "train_df = read_db_in_pandas(train_db)\n",
    "\n",
    "# format floating point numbers \n",
    "# within pandas data structures\n",
    "pd.set_option('float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rearrange the order of columns \n",
    "cols = train_df.columns.tolist()\n",
    "cols = cols[0:1] + cols[2:4] + cols[1:2] + cols[4:]\n",
    "train_df = train_df.ix[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 128 tracks in the dataset.\n",
      "37 tracks have no data available in the Echo Nest API.\n",
      "We are left with 91 tracks to use as training data.\n",
      "\n",
      "Below is a random sample of the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>category</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>The Sun I</td>\n",
       "      <td>Snakadaktal</td>\n",
       "      <td>yoga</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>-12.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>149.48</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Enima</td>\n",
       "      <td>Tim Hecker</td>\n",
       "      <td>focus</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>-11.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>79.04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Small Memory</td>\n",
       "      <td>Jon Hopkins</td>\n",
       "      <td>yoga</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-23.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>131.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Milk and honey</td>\n",
       "      <td>Jackson C Frank</td>\n",
       "      <td>focus</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.11</td>\n",
       "      <td>4</td>\n",
       "      <td>-13.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>106.55</td>\n",
       "      <td>4</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        song_title           artist category  acousticness  danceability  \\\n",
       "74       The Sun I      Snakadaktal     yoga          0.91          0.50   \n",
       "25           Enima       Tim Hecker    focus          0.24          0.15   \n",
       "66    Small Memory      Jon Hopkins     yoga          0.99          0.54   \n",
       "48  Milk and honey  Jackson C Frank    focus          0.95          0.48   \n",
       "\n",
       "    energy  instrumentalness  key  loudness  mode  speechiness  tempo  \\\n",
       "74    0.12              0.00    9    -12.84     0         0.04 149.48   \n",
       "25    0.68              0.94    1    -11.21     1         0.05  79.04   \n",
       "66    0.01              0.98    1    -23.04     1         0.10 131.28   \n",
       "48    0.17              0.11    4    -13.22     0         0.03 106.55   \n",
       "\n",
       "    time_signature  valence  \n",
       "74               3     0.15  \n",
       "25               3     0.23  \n",
       "66               4     0.46  \n",
       "48               4     0.32  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"There are {0} tracks in the dataset.\"\n",
    "       .format(len(train_db)))\n",
    "print (\"{0} tracks have no data available \"\n",
    "       \"in the Echo Nest API.\"\n",
    "       .format(len(train_db) - len(train_df)))\n",
    "print (\"We are left with {0} tracks to use as training data.\"\n",
    "       .format(len(train_df)))\n",
    "print \"\\nBelow is a random sample of the dataset.\"\n",
    "train_df.sample(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks in the dataset belong to 3 categories: cycling, focus, yoga.\n",
      "26 tracks represent 'cycling' category.\n",
      "34 tracks represent 'focus' category.\n",
      "31 tracks represent 'yoga' category.\n"
     ]
    }
   ],
   "source": [
    "# list of categories\n",
    "categories = list(pd.unique(train_df.category.ravel()))\n",
    "\n",
    "print (\"Tracks in the dataset belong \" \n",
    "       \"to {} categories: {}.\"\n",
    "       .format(len(categories), \", \".join(categories)))\n",
    "\n",
    "# count tracks in each category\n",
    "cat_count = pd.value_counts(train_df.category.ravel())\n",
    "\n",
    "# print categories\n",
    "for category in categories:\n",
    "    print (\"{} tracks represent \\'{}\\' category.\"\n",
    "           .format(cat_count[category], category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data overview\n",
    "\n",
    "Now I move on to the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 554 tracks in the dataset.\n",
      "223 tracks have no data available in the Echo Nest API.\n",
      "We are left with 331 tracks to use as a test set.\n",
      "\n",
      "Below is a random sample of the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Conner Youngblood</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>134.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>English Summer Rain</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>108.28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Strange Symmetry</td>\n",
       "      <td>Dakotafish</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2</td>\n",
       "      <td>-18.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>96.97</td>\n",
       "      <td>4</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Stuck On A Highway Island</td>\n",
       "      <td>Jane Jane Pollock</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>90.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    song_title             artist  acousticness  danceability  \\\n",
       "12                   Australia  Conner Youngblood          0.07          0.69   \n",
       "50         English Summer Rain            Placebo          0.00          0.58   \n",
       "246           Strange Symmetry         Dakotafish          0.27          0.51   \n",
       "247  Stuck On A Highway Island  Jane Jane Pollock          0.41          0.65   \n",
       "\n",
       "     energy  instrumentalness  key  loudness  mode  speechiness  tempo  \\\n",
       "12     0.50              0.69    0    -13.59     1         0.03 134.98   \n",
       "50     0.91              0.00   10     -7.90     0         0.05 108.28   \n",
       "246    0.42              0.92    2    -18.02     1         0.03  96.97   \n",
       "247    0.54              0.01    1     -7.18     0         0.03  90.01   \n",
       "\n",
       "     time_signature  valence  \n",
       "12                4     0.15  \n",
       "50                4     0.52  \n",
       "246               4     0.08  \n",
       "247               4     0.57  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a df with test data\n",
    "test_df = read_db_in_pandas(test_db)\n",
    "\n",
    "# rearrange the order of columns \n",
    "test_cols = test_df.columns.tolist()\n",
    "test_cols = test_cols[0:1] + test_cols[2:3] + test_cols[1:2] + test_cols[3:]\n",
    "test_df = test_df.ix[:, test_cols]\n",
    "\n",
    "print (\"There are {0} tracks in the dataset.\"\n",
    "       .format(len(test_db)))\n",
    "print (\"{0} tracks have no data available \" \n",
    "       \"in the Echo Nest API.\"\n",
    "       .format(len(test_db) - len(test_df)))\n",
    "print (\"We are left with {0} tracks to use as a test set.\"\n",
    "       .format(len(test_df)))\n",
    "print \"\\nBelow is a random sample of the dataset.\"\n",
    "test_df.sample(n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook I described data gathering and cleaning process for further analysis. I parsed iTunes music library xml file to create a database of tracks for the test dataset. I also transformed the csv file with labeled tracks into a sqlite3 database for the training set. Using the Echo Nest API I got track attributes for both sets.\n",
    "\n",
    "As a result of the above manipulations I created two pandas dataframes: \n",
    "* train dataframe contains 91 labeled tracks in three classes â \"cycling\", \"yoga\", \"ballet\";\n",
    "* test dataframe contains 331 non-labeled tracks. \n",
    "\n",
    "The next step in my analysis is to visualize both datasets and examine track attributes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
